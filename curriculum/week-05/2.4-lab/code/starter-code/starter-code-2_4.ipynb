{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Lab\n",
    "\n",
    "In the previous lab we have constructed a processing pipeline using `sklearn` for the titanic dataset. At this point you should have a set of features ready for consumption by a Logistic Regression model.\n",
    "\n",
    "In this la we will use the pre-processing pipeline you have created and combine it with a classification model.\n",
    "\n",
    "\n",
    "We have imported this titanic data into our PostgreSQL instance that you can find connecting here:\n",
    "\n",
    "    psql -h dsi.c20gkj5cvu3l.us-east-1.rds.amazonaws.com -p 5432 -U dsi_student titanic\n",
    "    password: gastudents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all let's load a few things:\n",
    "\n",
    "- standard packages\n",
    "- the training set from lab 2.3\n",
    "- the union we have saved in lab 2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, roc_curve, auc, f1_score\n",
    "import requests\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn import cross_validation\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "import patsy \n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression, Ridge, LogisticRegressionCV\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "import math\n",
    "from sklearn import preprocessing, svm\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from patsy import dmatrices\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('postgresql://dsi_student:gastudents@dsi.c20gkj5cvu3l.us-east-1.rds.amazonaws.com/titanic')\n",
    "\n",
    "df = pd.read_csv('/Users/smoot/Desktop/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import dill\n",
    "\n",
    "with gzip.open('../../../2.3-lab/assets/datasets/union.dill.gz') as fin:\n",
    "    union = dill.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('pipeline-1', Pipeline(steps=[('columnselector', ColumnSelector(columns='Age')), ('imputer', Imputer(axis=0, copy=True, missing_values='NaN', strategy='mean', verbose=0)), ('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True))])), ('getdummiestransformer', Ge...r(columns='Fare')), ('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True))]))],\n",
       "       transformer_weights=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, let's create the training and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = df[[u'Pclass', u'Sex', u'Age', u'SibSp', u'Parch', u'Fare', u'Embarked']]\n",
    "y = df['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Model Pipeline\n",
    "\n",
    "Combine the union you have created in the previous lab with a LogisticRegression instance. Notice that a `sklearn.pipeline` can have an arbitrary number of transformation steps, but only one, optional, estimator step as the last one in the chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline, make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80338983050847457"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([('union', union), ('clf', (LogisticRegression(penalty='l2')))])\n",
    "pipe.fit(X_train, y_train)\n",
    "score = pipe.score(X_test, y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train the model\n",
    "Use `X_train` and `y_train` to fit the model.\n",
    "Use `X_test` to generate predicted values for the target variable and save those in a new variable called `y_pred`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "709    False\n",
       "439     True\n",
       "840     True\n",
       "720     True\n",
       "39      True\n",
       "290     True\n",
       "300     True\n",
       "333     True\n",
       "208     True\n",
       "136     True\n",
       "137     True\n",
       "696     True\n",
       "485     True\n",
       "244     True\n",
       "344     True\n",
       "853     True\n",
       "621    False\n",
       "653     True\n",
       "886     True\n",
       "110     True\n",
       "294     True\n",
       "447    False\n",
       "192     True\n",
       "682     True\n",
       "538     True\n",
       "819     True\n",
       "30      True\n",
       "673    False\n",
       "63      True\n",
       "396     True\n",
       "       ...  \n",
       "456     True\n",
       "500     True\n",
       "430    False\n",
       "445    False\n",
       "650     True\n",
       "172     True\n",
       "450     True\n",
       "314     True\n",
       "332     True\n",
       "801     True\n",
       "90      True\n",
       "834     True\n",
       "181     True\n",
       "581     True\n",
       "795     True\n",
       "69      True\n",
       "131     True\n",
       "334     True\n",
       "597     True\n",
       "135     True\n",
       "164     True\n",
       "28      True\n",
       "783     True\n",
       "193    False\n",
       "869    False\n",
       "715     True\n",
       "525     True\n",
       "381     True\n",
       "140    False\n",
       "173     True\n",
       "Name: Survived, dtype: bool"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = pipe.predict(X_test)\n",
    "y_pred == y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluate the model accuracy\n",
    "\n",
    "1. Use the `confusion_matrix` and `classification_report` functions to assess the quality of the model.\n",
    "- Embed the results of the `confusion_matrix` in a Pandas dataframe with appropriate column names and index, so that it's easier to understand what kind of error the model is incurring into.\n",
    "- Are there more false positives or false negatives? (remember we are trying to predict survival)\n",
    "- How does that relate to what the `classification_report` is showing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, title='Confusion Matrix', cmap=plt.cm.Purples):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap = cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_didn't_survive</th>\n",
       "      <th>predicted_survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>didn't survive</th>\n",
       "      <td>154</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>survived</th>\n",
       "      <td>37</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                predicted_didn't_survive  predicted_survived\n",
       "didn't survive                       154                  21\n",
       "survived                              37                  83"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = np.array(confusion_matrix(y_test, y_pred))\n",
    "confusion = pd.DataFrame(cm, index=['didn\\'t survive', 'survived'],\n",
    "                         columns=['predicted_didn\\'t_survive','predicted_survived'])\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVkAAAEmCAYAAADIhuPPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzKxETrJmZiVykjUzK5GTrJlZif4/wCKswsAWdX0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1184e6790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plot_confusion_matrix(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.88      0.84       175\n",
      "          1       0.80      0.69      0.74       120\n",
      "\n",
      "avg / total       0.80      0.80      0.80       295\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:  0.803389830508\n",
      "precision score:  0.798076923077\n",
      "recall score 0.691666666667\n",
      "f1 score:  0.741071428571\n"
     ]
    }
   ],
   "source": [
    "print \"accuracy score: \", accuracy_score(y_test, y_pred)\n",
    "print 'precision score: ', precision_score(y_test, y_pred)\n",
    "print 'recall score', recall_score(y_test, y_pred)\n",
    "print 'f1 score: ', f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pipe.get_params().keys()\n",
    "scores = cross_validation.cross_val_score(lr, X_, y, scoring='accuracy', cv=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>died_pp</th>\n",
       "      <th>survived_pp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.824613</td>\n",
       "      <td>0.175387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.743103</td>\n",
       "      <td>0.256897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.900069</td>\n",
       "      <td>0.099931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.141620</td>\n",
       "      <td>0.858380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.255807</td>\n",
       "      <td>0.744193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.149882</td>\n",
       "      <td>0.850118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.383103</td>\n",
       "      <td>0.616897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.890464</td>\n",
       "      <td>0.109536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.320384</td>\n",
       "      <td>0.679616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.145710</td>\n",
       "      <td>0.854290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.700574</td>\n",
       "      <td>0.299426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.936241</td>\n",
       "      <td>0.063759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.511942</td>\n",
       "      <td>0.488058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.828394</td>\n",
       "      <td>0.171606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.761121</td>\n",
       "      <td>0.238879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.135041</td>\n",
       "      <td>0.864959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.721729</td>\n",
       "      <td>0.278271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.383064</td>\n",
       "      <td>0.616936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.726203</td>\n",
       "      <td>0.273797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.741943</td>\n",
       "      <td>0.258057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.907169</td>\n",
       "      <td>0.092831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.699352</td>\n",
       "      <td>0.300648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.467542</td>\n",
       "      <td>0.532458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.899825</td>\n",
       "      <td>0.100175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.915165</td>\n",
       "      <td>0.084835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.875731</td>\n",
       "      <td>0.124269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.533727</td>\n",
       "      <td>0.466273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.742107</td>\n",
       "      <td>0.257893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.861803</td>\n",
       "      <td>0.138197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.528595</td>\n",
       "      <td>0.471405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>0.813951</td>\n",
       "      <td>0.186049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>0.894289</td>\n",
       "      <td>0.105711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>0.673038</td>\n",
       "      <td>0.326962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>0.529390</td>\n",
       "      <td>0.470610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>0.916227</td>\n",
       "      <td>0.083773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>0.376690</td>\n",
       "      <td>0.623310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>0.755489</td>\n",
       "      <td>0.244511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>0.781404</td>\n",
       "      <td>0.218596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>0.659558</td>\n",
       "      <td>0.340442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>0.217819</td>\n",
       "      <td>0.782181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>0.915376</td>\n",
       "      <td>0.084624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>0.896270</td>\n",
       "      <td>0.103730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>0.548280</td>\n",
       "      <td>0.451720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>0.085780</td>\n",
       "      <td>0.914220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>0.772057</td>\n",
       "      <td>0.227943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>0.910415</td>\n",
       "      <td>0.089585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>0.900232</td>\n",
       "      <td>0.099768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>0.144570</td>\n",
       "      <td>0.855430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>0.942968</td>\n",
       "      <td>0.057032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>0.515184</td>\n",
       "      <td>0.484816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>0.851278</td>\n",
       "      <td>0.148722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>0.383040</td>\n",
       "      <td>0.616960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>0.913706</td>\n",
       "      <td>0.086294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>0.612854</td>\n",
       "      <td>0.387146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>0.865911</td>\n",
       "      <td>0.134089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>0.898273</td>\n",
       "      <td>0.101727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>0.886451</td>\n",
       "      <td>0.113549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>0.207157</td>\n",
       "      <td>0.792843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>0.318679</td>\n",
       "      <td>0.681321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>0.901886</td>\n",
       "      <td>0.098114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>295 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      died_pp  survived_pp\n",
       "0    0.824613     0.175387\n",
       "1    0.743103     0.256897\n",
       "2    0.900069     0.099931\n",
       "3    0.141620     0.858380\n",
       "4    0.255807     0.744193\n",
       "5    0.149882     0.850118\n",
       "6    0.383103     0.616897\n",
       "7    0.890464     0.109536\n",
       "8    0.320384     0.679616\n",
       "9    0.145710     0.854290\n",
       "10   0.700574     0.299426\n",
       "11   0.936241     0.063759\n",
       "12   0.511942     0.488058\n",
       "13   0.828394     0.171606\n",
       "14   0.761121     0.238879\n",
       "15   0.135041     0.864959\n",
       "16   0.721729     0.278271\n",
       "17   0.383064     0.616936\n",
       "18   0.726203     0.273797\n",
       "19   0.741943     0.258057\n",
       "20   0.907169     0.092831\n",
       "21   0.699352     0.300648\n",
       "22   0.467542     0.532458\n",
       "23   0.899825     0.100175\n",
       "24   0.915165     0.084835\n",
       "25   0.875731     0.124269\n",
       "26   0.533727     0.466273\n",
       "27   0.742107     0.257893\n",
       "28   0.861803     0.138197\n",
       "29   0.528595     0.471405\n",
       "..        ...          ...\n",
       "265  0.813951     0.186049\n",
       "266  0.894289     0.105711\n",
       "267  0.673038     0.326962\n",
       "268  0.529390     0.470610\n",
       "269  0.916227     0.083773\n",
       "270  0.376690     0.623310\n",
       "271  0.755489     0.244511\n",
       "272  0.781404     0.218596\n",
       "273  0.659558     0.340442\n",
       "274  0.217819     0.782181\n",
       "275  0.915376     0.084624\n",
       "276  0.896270     0.103730\n",
       "277  0.548280     0.451720\n",
       "278  0.085780     0.914220\n",
       "279  0.772057     0.227943\n",
       "280  0.910415     0.089585\n",
       "281  0.900232     0.099768\n",
       "282  0.144570     0.855430\n",
       "283  0.942968     0.057032\n",
       "284  0.515184     0.484816\n",
       "285  0.851278     0.148722\n",
       "286  0.383040     0.616960\n",
       "287  0.913706     0.086294\n",
       "288  0.612854     0.387146\n",
       "289  0.865911     0.134089\n",
       "290  0.898273     0.101727\n",
       "291  0.886451     0.113549\n",
       "292  0.207157     0.792843\n",
       "293  0.318679     0.681321\n",
       "294  0.901886     0.098114\n",
       "\n",
       "[295 rows x 2 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pp = pd.DataFrame(pipe.predict_proba(X_test), columns=['died_pp','survived_pp'])\n",
    "y_pp['binary'] = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Improving the model\n",
    "\n",
    "Can we improve the accuracy of the model?\n",
    "\n",
    "One way to do this is to use tune the parameters controlling it.\n",
    "\n",
    "You can get a list of all the model parameters using `model.get_params().keys()`.\n",
    "\n",
    "Discuss with your team which parameters you could try to change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can systematically probe parameter combinations by using the `GridSearchCV` function. Implement a new classifier that searches the best parameter combination.\n",
    "\n",
    "1. How will you choose the grid granularity?\n",
    "1. How can you prevent the grid to exponentially grow?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Assess the tuned model\n",
    "\n",
    "A tuned grid search model stores the best parameter combination and the best estimator as attributes.\n",
    "\n",
    "1. Use these to generate a new prediction vector `y_pred`.\n",
    "- Use the `confusion matrix`and `classification_report` to assess the accuracy of the new model.\n",
    "- How does the new model compare with the old one?\n",
    "- What else could you do to improve the accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "\n",
    "What would happen if we used a different scoring function? Would our results change?\n",
    "Choose one or two classification metrics from the [sklearn provided metrics](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics) and repeat the grid_search. Do your result change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
