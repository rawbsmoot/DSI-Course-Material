{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, roc_curve, auc, f1_score\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import Imputer, StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from lxml import html\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib2\n",
    "from sklearn.svm import SVC\n",
    "import re\n",
    "import patsy \n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression, Ridge, LogisticRegressionCV\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "import math\n",
    "from sklearn import preprocessing, svm\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab we will explore several datasets with SVMs. The assets folder contains several datasets (in order of complexity):\n",
    "\n",
    "1. Breast cancer\n",
    "- Spambase\n",
    "- Car evaluation\n",
    "- Mushroom\n",
    "\n",
    "For each of these a `.names` file is provided with details on the origin of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample_code_number</th>\n",
       "      <th>Clump_Thickness</th>\n",
       "      <th>Uniformity_of_Cell_Size</th>\n",
       "      <th>Uniformity_of_Cell_Shape</th>\n",
       "      <th>Marginal_Adhesion</th>\n",
       "      <th>Single_Epithelial_Cell_Size</th>\n",
       "      <th>Bare_Nuclei</th>\n",
       "      <th>Bland_Chromatin</th>\n",
       "      <th>Normal_Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000025</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002945</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1015425</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1016277</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1017023</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sample_code_number  Clump_Thickness  Uniformity_of_Cell_Size  \\\n",
       "0             1000025                5                        1   \n",
       "1             1002945                5                        4   \n",
       "2             1015425                3                        1   \n",
       "3             1016277                6                        8   \n",
       "4             1017023                4                        1   \n",
       "\n",
       "   Uniformity_of_Cell_Shape  Marginal_Adhesion  Single_Epithelial_Cell_Size  \\\n",
       "0                         1                  1                            2   \n",
       "1                         4                  5                            7   \n",
       "2                         1                  1                            2   \n",
       "3                         8                  1                            3   \n",
       "4                         1                  3                            2   \n",
       "\n",
       "   Bare_Nuclei  Bland_Chromatin  Normal_Nucleoli  Mitoses  Class  \n",
       "0          1.0                3                1        1      2  \n",
       "1         10.0                3                2        1      2  \n",
       "2          2.0                3                1        1      2  \n",
       "3          4.0                3                7        1      2  \n",
       "4          1.0                3                1        1      2  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/smoot/Desktop/breast_cancer.csv', na_values = '?')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Class.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: Breast Cancer\n",
    "\n",
    "\n",
    "\n",
    "## 1.a: Load the Data\n",
    "Use `pandas.read_csv` to load the data and assess the following:\n",
    "- Are there any missing values? (how are they encoded? do we impute them?)\n",
    "- Are the features categorical or numerical?\n",
    "- Are the values normalized?\n",
    "- How many classes are there in the target?\n",
    "\n",
    "Perform what's necessary to get to a point where you have a feature matrix `X` and a target vector `y`, both with only numerical entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()\n",
    "df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      False\n",
       "1      False\n",
       "2      False\n",
       "3      False\n",
       "4      False\n",
       "5       True\n",
       "6      False\n",
       "7      False\n",
       "8      False\n",
       "9      False\n",
       "10     False\n",
       "11     False\n",
       "12      True\n",
       "13     False\n",
       "14      True\n",
       "15      True\n",
       "16     False\n",
       "17     False\n",
       "18      True\n",
       "19     False\n",
       "20      True\n",
       "21      True\n",
       "22     False\n",
       "24     False\n",
       "25      True\n",
       "26     False\n",
       "27     False\n",
       "28     False\n",
       "29     False\n",
       "30     False\n",
       "       ...  \n",
       "669     True\n",
       "670     True\n",
       "671    False\n",
       "672    False\n",
       "673    False\n",
       "674    False\n",
       "675    False\n",
       "676    False\n",
       "677    False\n",
       "678    False\n",
       "679    False\n",
       "680     True\n",
       "681     True\n",
       "682    False\n",
       "683    False\n",
       "684    False\n",
       "685    False\n",
       "686    False\n",
       "687    False\n",
       "688    False\n",
       "689    False\n",
       "690    False\n",
       "691     True\n",
       "692    False\n",
       "693    False\n",
       "694    False\n",
       "695    False\n",
       "696     True\n",
       "697     True\n",
       "698     True\n",
       "Name: Class, dtype: bool"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(['Sample_code_number', 'Class'], axis = 1)\n",
    "# df[''] = [0 if i < 85000  else 1 for i in df.salary]\n",
    "y = df[\"Class\"] == 4\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.b: Model Building\n",
    "\n",
    "- What's the baseline for the accuracy?\n",
    "- Initialize and train a linear svm. What's the average accuracy score with a 3-fold cross validation?\n",
    "- Repeat using an rbf classifier. Compare the scores. Which one is better?\n",
    "- Are your features normalized? if not, try normalizing and repeat the test. Does the score improve?\n",
    "- What's the best model?\n",
    "- Print a confusion matrix and classification report for your best model using:\n",
    "        train_test_split(X, y, stratify=y, test_size=0.33, random_state=42)\n",
    "\n",
    "**Check** to decide which model is best, look at the average cross validation score. Are the scores significantly different from one another?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    0.650073\n",
       "True     0.349927\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts() / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Average score: 0.965+/-0.0179\n"
     ]
    }
   ],
   "source": [
    "all_scores = []\n",
    "model = SVC(kernel = 'linear')\n",
    "\n",
    "def do_cv(model, X, y, cv):\n",
    "    scores = cross_val_score(model, X, y, cv = cv)\n",
    "    print model\n",
    "    sm = scores.mean()\n",
    "    ss = scores.std()\n",
    "    res = (sm, ss)\n",
    "    print 'Average score: {:0.3}+/-{:0.3}'.format(*res)\n",
    "    return res\n",
    "all_scores.append(do_cv(model, X, y, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Average score: 0.958+/-0.0251\n"
     ]
    }
   ],
   "source": [
    "model = SVC(kernel = 'rbf')\n",
    "all_scores.append(do_cv(model, X, y, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('svc', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "Average score: 0.966+/-0.0161\n"
     ]
    }
   ],
   "source": [
    "model = make_pipeline(StandardScaler(), SVC(kernel = 'linear'))\n",
    "all_scores.append(do_cv(model, X, y, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('svc', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "Average score: 0.968+/-0.018\n"
     ]
    }
   ],
   "source": [
    "model = make_pipeline(StandardScaler(), SVC())\n",
    "all_scores.append(do_cv(model, X, y, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check:** Are there more false positives or false negatives? Is this good or bad?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.c: Feature Selection\n",
    "\n",
    "Use any of the strategies offered by `sklearn` to select the most important features.\n",
    "\n",
    "Repeat the cross validation with only those 5 features. Does the score change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.d: Learning Curves\n",
    "\n",
    "Learning curves are useful to study the behavior of training and test errors as a function of the number of datapoints available.\n",
    "\n",
    "- Plot learning curves for train sizes between 10% and 100% (use StratifiedKFold with 5 folds as cross validation)\n",
    "- What can you say about the dataset? do you need more data or do you need a better model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1.e: Grid Ssearch\n",
    "\n",
    "Use the grid_search function to explore different kernels and values for the C parameter.\n",
    "\n",
    "- Can you improve on your best previous score?\n",
    "- Print the best parameters and the best score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "Now that you've completed steps 1.a through 1.e it's time to tackle some harder datasets. But before we do that, let's encapsulate a few things into functions so that it's easier to repeat the analysis.\n",
    "\n",
    "## 2.a: Cross Validation\n",
    "Implement a function `do_cv(model, X, y, cv)` that does the following:\n",
    "- Calculates the cross validation scores\n",
    "- Prints the model\n",
    "- Prints and returns the mean and the standard deviation of the cross validation scores\n",
    "\n",
    "> Answer: see above\n",
    "\n",
    "## 2.b: Confusion Matrix and Classification report\n",
    "Implement a function `do_cm_cr(model, X, y, names)` that automates the following:\n",
    "- Split the data using `train_test_split(X, y, stratify=y, test_size=0.33, random_state=42)`\n",
    "- Fit the model\n",
    "- Prints confusion matrix and classification report in a nice format\n",
    "\n",
    "**Hint:** names is the list of target classes\n",
    "\n",
    "> Answer: see above\n",
    "\n",
    "## 2.c: Learning Curves\n",
    "Implement a function `do_learning_curve(model, X, y, sizes)` that automates drawing the learning curves:\n",
    "- Allow for sizes input\n",
    "- Use 5-fold StratifiedKFold cross validation\n",
    "\n",
    "> Answer: see above\n",
    "\n",
    "## 2.d: Grid Search\n",
    "Implement a function `do_grid_search(model, parameters)` that automates the grid search by doing:\n",
    "- Calculate grid search\n",
    "- Print best parameters\n",
    "- Print best score\n",
    "- Return best estimator\n",
    "\n",
    "\n",
    "> Answer: see above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3\n",
    "Using the functions above, analyze the Spambase dataset.\n",
    "\n",
    "Notice that now you have many more features. Focus your attention on step C => feature selection\n",
    "\n",
    "- Load the data and get to X, y\n",
    "- Select the 15 best features\n",
    "- Perform grid search to determine best model\n",
    "- Display learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4\n",
    "Repeat steps 1.a - 1.e for the car dataset. Notice that now features are categorical, not numerical.\n",
    "- Find a suitable way to encode them\n",
    "- How does this change our modeling strategy?\n",
    "\n",
    "Also notice that the target variable `acceptability` has 4 classes. How do we encode them?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus\n",
    "Repeat steps 1.a - 1.e for the mushroom dataset. Notice that now features are categorical, not numerical. This dataset is quite large.\n",
    "- How does this change our modeling strategy?\n",
    "- Can we use feature selection to improve this?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
